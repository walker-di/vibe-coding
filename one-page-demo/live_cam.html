<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC Pixi.js Recorder V2</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/6.5.10/browser/pixi.min.js"></script>
    <style>
        /* Base styles from previous version */
        body {
            font-family: sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            background-color: #f0f0f0;
            margin: 0;
        }
        .container {
            max-width: 1200px;
            width: 95%;
            margin: 0 auto;
        }
        .video-container {
            position: relative;
            margin-bottom: 20px;
            width: 100%;
            max-width: 640px;
            margin-left: auto;
            margin-right: auto;
            aspect-ratio: 640 / 480;
            background-color: #cccccc; /* Default light grey background */
            border: 1px solid #999;
            overflow: hidden; /* Hide parts of video/bg if they go outside */
        }
        #webcamVideo { display: none; }
        #pixiCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            /* border: 1px solid black; */ /* Border now on container */
            pointer-events: auto;
            cursor: default; /* Default cursor for canvas */
        }
        .controls, .toolbar {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-bottom: 20px;
            width: 100%;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
        }
         .toolbar {
            flex-direction: column;
            background-color: #fff;
            border-radius: 8px;
            padding: 15px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .toolbar-section {
            margin-bottom: 15px;
            width: 100%;
        }
         h1, h2 {
             text-align: center;
             color: #333;
             margin-top: 0;
             margin-bottom: 15px; /* Added margin */
         }
         h2 { font-size: 18px; text-align: left; border-bottom: 1px solid #eee; padding-bottom: 5px; margin-bottom: 10px;}
         button {
            background-color: #4285f4;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
            transition: background-color 0.2s ease;
        }
        button:hover:not(:disabled) { background-color: #3367d6; }
        button:disabled { background-color: #ccc; cursor: not-allowed; }

        /* Control groups styling */
        .control-group { /* General purpose flex container for controls */
             display: flex;
             flex-wrap: wrap;
             align-items: center;
             gap: 10px;
             margin-bottom: 10px;
        }
         label { margin-right: 5px; font-weight: bold; font-size: 14px; }
         input[type="text"], input[type="number"], select, input[type="file"] {
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 14px;
         }
         input[type="color"].color-picker {
            width: 40px;
            height: 36px;
            padding: 2px;
            border: 1px solid #ddd;
            border-radius: 4px;
            cursor: pointer;
         }
         input[type="range"] {
             cursor: pointer;
             flex-grow: 1; /* Allow slider to take up space */
             min-width: 150px;
         }
        .shape-btn {
            width: 40px;
            height: 40px;
            margin-right: 5px;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            padding: 0;
            background-color: #e0e0e0;
            color: #333;
        }
         .shape-btn:hover:not(:disabled) { background-color: #bdbdbd; }
         .shape-preview { font-size: 18px; }

        .sfx-button {
            background-color: #ff7043;
            min-width: 100px;
        }
        .sfx-button:hover:not(:disabled) { background-color: #f4511e; }

        #downloadLink {
            display: none;
            margin-top: 15px;
            padding: 10px 20px;
            background-color: #4CAF50;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            text-align: center;
        }
        .recording {
            background-color: #f44336 !important;
            color: white;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
             0% { box-shadow: 0 0 0 0 rgba(244, 67, 54, 0.7); }
             70% { box-shadow: 0 0 0 10px rgba(244, 67, 54, 0); }
             100% { box-shadow: 0 0 0 0 rgba(244, 67, 54, 0); }
        }

        /* Style for file input */
        input[type="file"] {
            border: none;
            padding: 0;
        }
        input[type="file"]::file-selector-button {
             background-color: #6c757d;
             color: white;
             border: none;
             padding: 8px 12px;
             border-radius: 4px;
             cursor: pointer;
             margin-right: 10px;
             transition: background-color 0.2s ease;
        }
        input[type="file"]::file-selector-button:hover {
             background-color: #5a6268;
        }

    </style>
</head>
<body>
    <div class="container">
        <h1>WebRTC + Pixi.js Recorder V2</h1>

        <video id="webcamVideo" playsinline autoplay muted></video>

        <div class="video-container">
            <canvas id="pixiCanvas"></canvas>
        </div>

        <div class="controls">
            <button id="startCamBtn">Start Camera</button>
            <button id="startRecBtn" disabled>Start Recording</button>
            <button id="stopRecBtn" disabled>Stop Recording</button>
            <a id="downloadLink" download="recording.webm">Download Recording</a>
        </div>

        <div class="toolbar">
            <!-- Background Controls -->
            <div class="toolbar-section">
                <h2>Background</h2>
                <div class="control-group">
                    <label for="bgSelect">Preset:</label>
                    <select id="bgSelect">
                        <option value="color">Color</option>
                        <option value="office.jpg">Office</option> <!-- Replace with actual URLs -->
                        <option value="space.jpg">Space</option> <!-- Replace with actual URLs -->
                        <option value="gradient.png">Gradient</option> <!-- Replace with actual URLs -->
                    </select>
                    <input type="color" id="bgColorPicker" class="color-picker" value="#cccccc">
                     <label for="bgUpload">Upload:</label>
                    <input type="file" id="bgUpload" accept="image/*">
                </div>
            </div>

             <!-- Camera View Controls -->
            <div class="toolbar-section">
                <h2>Camera View</h2>
                <div class="control-group">
                     <label for="cameraScale">Scale:</label>
                     <input type="range" id="cameraScale" min="0.2" max="2.0" step="0.05" value="1.0">
                     <span id="cameraScaleValue">1.0x</span>
                     <button id="resetViewBtn">Reset View</button>
                </div>
                 <small style="display: block; margin-top: -5px; color: #666;">Click and drag the camera view to reposition it.</small>
            </div>

            <!-- Text Controls -->
            <div class="toolbar-section">
                <h2>Text & Shapes</h2>
                <div class="control-group">
                    <label>Text:</label>
                    <input type="text" id="textInput" placeholder="Enter text">
                    <input type="number" id="textSize" min="12" max="72" value="24" title="Size">
                    <input type="color" id="textColor" class="color-picker" value="#FFFF00" title="Color">
                    <button id="addTextBtn" title="Add Text">+</button>
                </div>
                 <div class="control-group">
                    <label>Shapes:</label>
                    <button class="shape-btn" data-shape="circle" title="Circle"><span class="shape-preview">‚ö™</span></button>
                    <button class="shape-btn" data-shape="rectangle" title="Rectangle"><span class="shape-preview">‚ñ¢</span></button>
                    <button class="shape-btn" data-shape="triangle" title="Triangle"><span class="shape-preview">‚ñ≥</span></button>
                    <button class="shape-btn" data-shape="star" title="Star"><span class="shape-preview">‚òÖ</span></button>
                    <input type="color" id="shapeColor" class="color-picker" value="#ff0000" title="Color">
                    <input type="number" id="shapeSize" min="10" max="200" value="50" title="Size">
                     <button id="clearGraphicsBtn" style="margin-left: auto;" title="Clear Text & Shapes">Clear All</button>
                 </div>
                 <small style="display: block; margin-top: -5px; color: #666;">Click and drag text/shapes to reposition.</small>
            </div>

            <!-- Audio Controls -->
            <div class="toolbar-section">
                <h2>Audio</h2>
                <div class="control-group">
                     <label>SFX:</label>
                     <button class="sfx-button" data-sfx="applause">üëè</button> <!-- Icons or shorter text -->
                     <button class="sfx-button" data-sfx="drumroll">ü•Å</button>
                     <button class="sfx-button" data-sfx="bell">üîî</button>
                     <button class="sfx-button" data-sfx="laugh">üòÑ</button>
                 </div>
                 <div class="control-group">
                    <label for="bgmSelect">BGM:</label>
                    <select id="bgmSelect">
                        <option value="none">None</option>
                        <option value="upbeat">Upbeat</option>
                        <option value="relaxed">Relaxed</option>
                        <option value="dramatic">Dramatic</option>
                    </select>
                    <label for="bgmVolume">Vol:</label>
                    <input type="range" id="bgmVolume" min="0" max="1" step="0.05" value="0.3">
                 </div>
            </div>
        </div>
    </div>

    <script>
        // --- Configuration ---
        const CANVAS_WIDTH = 640;
        const CANVAS_HEIGHT = 480;
        // IMPORTANT: Add URLs for your preset backgrounds here
        const PRESET_BACKGROUNDS = {
            'office.jpg': 'https://via.placeholder.com/640x480/aabbcc/888888?text=Office+BG', // Replace with your actual image URL
            'space.jpg': 'https://via.placeholder.com/640x480/000033/ffffff?text=Space+BG',   // Replace with your actual image URL
            'gradient.png': 'https://via.placeholder.com/640x480/ffccaa/aa66cc?text=Gradient+BG' // Replace with your actual image URL
        };

        // --- Global Variables ---
        let pixiApp;
        let webcamVideoElement = document.getElementById('webcamVideo');
        let pixiCanvasElement = document.getElementById('pixiCanvas');
        let backgroundSprite; // Sprite for the background image
        let videoSprite; // Sprite for the webcam video
        let graphicsContainer; // Container for text/shapes

        let mediaRecorder;
        let recordedChunks = [];
        let combinedStream = null;
        let webcamStream = null;

        // Audio related
        let audioContext;
        let micSourceNode, micGainNode;
        let sfxGainNode;
        let bgmGainNode;
        let destinationNode;
        let sfxSounds = {};
        let bgmSounds = {};
        let currentBgmInterval = null;
        let bgmOscillators = [];

        // UI Elements
        const startCamBtn = document.getElementById('startCamBtn');
        const startRecBtn = document.getElementById('startRecBtn');
        const stopRecBtn = document.getElementById('stopRecBtn');
        const downloadLink = document.getElementById('downloadLink');
        // Background
        const bgSelect = document.getElementById('bgSelect');
        const bgColorPicker = document.getElementById('bgColorPicker');
        const bgUpload = document.getElementById('bgUpload');
        // Camera View
        const cameraScaleSlider = document.getElementById('cameraScale');
        const cameraScaleValueSpan = document.getElementById('cameraScaleValue');
        const resetViewBtn = document.getElementById('resetViewBtn');
        // Text
        const addTextBtn = document.getElementById('addTextBtn');
        const textInput = document.getElementById('textInput');
        const textSize = document.getElementById('textSize');
        const textColor = document.getElementById('textColor');
        // Shapes
        const shapeButtons = document.querySelectorAll('.shape-btn');
        const shapeColor = document.getElementById('shapeColor');
        const shapeSize = document.getElementById('shapeSize');
        const clearGraphicsBtn = document.getElementById('clearGraphicsBtn');
        // Audio
        const sfxButtons = document.querySelectorAll('.sfx-button');
        const bgmSelect = document.getElementById('bgmSelect');
        const bgmVolume = document.getElementById('bgmVolume');

        // Drag state
        let dragTarget = null;


        // --- Initialization ---
        async function initCamera() {
             if (webcamStream) return;
             try {
                webcamStream = await navigator.mediaDevices.getUserMedia({
                    video: { width: CANVAS_WIDTH, height: CANVAS_HEIGHT }, // Request preferred size
                    audio: true
                });
                webcamVideoElement.srcObject = webcamStream;
                await webcamVideoElement.play();

                const actualWidth = webcamVideoElement.videoWidth || CANVAS_WIDTH;
                const actualHeight = webcamVideoElement.videoHeight || CANVAS_HEIGHT;

                const videoContainer = document.querySelector('.video-container');
                videoContainer.style.aspectRatio = `${actualWidth} / ${actualHeight}`;

                if (!pixiApp) {
                    setupPixi(actualWidth, actualHeight);
                } else {
                    pixiApp.renderer.resize(actualWidth, actualHeight);
                    // Re-setup sprites if dimensions change drastically? Or just resize?
                    // Let's assume resize is sufficient for now.
                    backgroundSprite.width = actualWidth;
                    backgroundSprite.height = actualHeight;
                    // Keep video sprite's potentially modified scale/position
                    // videoSprite.width = actualWidth; // Don't reset width/height if scaled
                    // videoSprite.height = actualHeight;
                }

                if (!audioContext) setupAudio();
                setupEventListeners();

                startCamBtn.disabled = true;
                startRecBtn.disabled = false;
                console.log("Camera and Mic initialized.");

             } catch (err) {
                 console.error("Error accessing media devices.", err);
                 alert(`Error accessing media devices: ${err.name}\n${err.message}`);
                 startCamBtn.disabled = false;
             }
        }

        // --- Pixi.js Setup ---
        function setupPixi(width, height) {
            pixiApp = new PIXI.Application({
                view: pixiCanvasElement,
                width: width,
                height: height,
                // backgroundColor managed by background controls now
                resolution: window.devicePixelRatio || 1,
                autoDensity: true,
                antialias: true,
                transparent: true // Keep transparent for background color to show through
            });

            // 1. Background Layer (added first)
            backgroundSprite = new PIXI.Sprite(); // Initially empty
            backgroundSprite.width = width;
            backgroundSprite.height = height;
            backgroundSprite.anchor.set(0); // Top-left anchor
            pixiApp.stage.addChildAt(backgroundSprite, 0);
            updateBackground(); // Set initial background based on controls

            // 2. Video Layer
            const videoTexture = PIXI.Texture.from(webcamVideoElement);
            videoSprite = new PIXI.Sprite(videoTexture);
            videoSprite.width = width; // Initial full size
            videoSprite.height = height;
            videoSprite.anchor.set(0); // Top-left anchor for easier scaling/positioning calc
            videoSprite.x = 0;
            videoSprite.y = 0;

            // Make video draggable
            videoSprite.interactive = true;
            videoSprite.buttonMode = true; // Show pointer cursor
            videoSprite.cursor = 'move'; // Explicit move cursor
            videoSprite
                .on('pointerdown', onDragStart)
                .on('pointerup', onDragEnd)
                .on('pointerupoutside', onDragEnd)
                .on('pointermove', onDragMove);

            pixiApp.stage.addChildAt(videoSprite, 1); // Add video above background

            // 3. Graphics Overlay Layer (added last/top)
             graphicsContainer = new PIXI.Container();
             graphicsContainer.interactive = true; // Allow interaction for children
             pixiApp.stage.addChildAt(graphicsContainer, 2); // Add graphics above video


            // Ticker for video texture update
            pixiApp.ticker.add(() => {
                if (webcamVideoElement.readyState >= webcamVideoElement.HAVE_CURRENT_DATA) {
                     try {
                         videoTexture.update();
                     } catch (e) {
                         console.warn("Error updating video texture (possible context loss?)", e);
                         // Potential recovery logic? For now, just log.
                     }
                }
            });

            console.log("PixiJS setup complete with layers: Background, Video, Graphics");
        }

        // --- Web Audio API Setup (no changes needed here) ---
        function setupAudio() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            destinationNode = audioContext.createMediaStreamDestination();

            // Mic
            if (webcamStream && webcamStream.getAudioTracks().length > 0) {
                micSourceNode = audioContext.createMediaStreamSource(webcamStream);
                micGainNode = audioContext.createGain(); micGainNode.gain.value = 1.0;
                micSourceNode.connect(micGainNode).connect(destinationNode);
                micGainNode.connect(audioContext.destination); // Also connect to output
                console.log("Microphone connected.");
            } else { console.warn("No mic track found."); }

            // SFX Gain
            sfxGainNode = audioContext.createGain(); sfxGainNode.gain.value = 0.6;
            sfxGainNode.connect(destinationNode);
            sfxGainNode.connect(audioContext.destination);
            initSfxSounds(); console.log("SFX node ready.");

            // BGM Gain
            bgmGainNode = audioContext.createGain(); bgmGainNode.gain.value = parseFloat(bgmVolume.value);
            bgmGainNode.connect(destinationNode);
            bgmGainNode.connect(audioContext.destination);
            initBgmSounds(); console.log("BGM node ready.");
        }

        // --- Synthesized Audio Generation (no changes needed here) ---
        function initSfxSounds() { /* ... (same as before) ... */
             const sfxData = { applause: [0.3, 0.7, 0.2, 0.4, 0.6, 0.8, 0.4, 0.6, 0.2, 0.4], drumroll: [0.2, 0.6, 0.2, 0.6, 0.2, 0.6, 0.2, 0.8, 0.9, 1.0], bell: [1.0, 0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0], laugh: [0.3, 0.5, 0.7, 0.5, 0.3, 0.5, 0.7, 0.5, 0.3] };
             Object.keys(sfxData).forEach(name => {
                 sfxSounds[name] = () => {
                     if (!audioContext) return; if (audioContext.state === 'suspended') { audioContext.resume(); }
                     const now = audioContext.currentTime; const osc = audioContext.createOscillator(); const gainNode = audioContext.createGain();
                     osc.type = name === 'bell' ? 'sine' : (name === 'drumroll' ? 'noise' : 'square');
                     if (osc.type !== 'noise') { osc.frequency.value = name === 'bell' ? 880 : (name === 'laugh' ? 440 : 110); }
                     osc.connect(gainNode); gainNode.connect(sfxGainNode); osc.start(now);
                     const duration = name === 'drumroll' ? 0.05 : 0.1; const pattern = sfxData[name]; gainNode.gain.setValueAtTime(0, now);
                     pattern.forEach((value, i) => { gainNode.gain.linearRampToValueAtTime(value * 0.5, now + (i + 0.5) * duration); });
                     gainNode.gain.setValueAtTime(pattern[pattern.length - 1] * 0.5, now + pattern.length * duration); gainNode.gain.linearRampToValueAtTime(0, now + pattern.length * duration + 0.1);
                     osc.stop(now + pattern.length * duration + 0.15);
                 };
             });
        }
        function initBgmSounds() { /* ... (same as before) ... */
             const bgmPatterns = { upbeat: { notes: [440, 0, 493.88, 0, 523.25, 587.33, 659.25, 523.25], duration: 0.15, type: 'square' }, relaxed: { notes: [261.63, 0, 329.63, 0, 392, 0, 329.63, 0], duration: 0.4, type: 'sine' }, dramatic: { notes: [130.81, 146.83, 0, 130.81, 0, 98, 123.47, 98], duration: 0.3, type: 'sawtooth' } };
             Object.keys(bgmPatterns).forEach(name => {
                 const pattern = bgmPatterns[name];
                 bgmSounds[name] = () => {
                     stopCurrentBgm(); if (!audioContext) return; if (audioContext.state === 'suspended') { audioContext.resume(); }
                     let noteIndex = 0; bgmOscillators = [];
                     const playBgmNotes = () => {
                         const now = audioContext.currentTime; const noteFrequency = pattern.notes[noteIndex % pattern.notes.length];
                         if (noteFrequency > 0) {
                             const osc = audioContext.createOscillator(); const gain = audioContext.createGain();
                             osc.type = pattern.type; osc.frequency.setValueAtTime(noteFrequency, now); gain.gain.setValueAtTime(0, now);
                             gain.gain.linearRampToValueAtTime(1.0, now + 0.02); gain.gain.setValueAtTime(1.0, now + pattern.duration * 0.8); gain.gain.linearRampToValueAtTime(0, now + pattern.duration);
                             osc.connect(gain); gain.connect(bgmGainNode); osc.start(now); osc.stop(now + pattern.duration); bgmOscillators.push(osc);
                         } noteIndex++;
                     }; playBgmNotes(); currentBgmInterval = setInterval(playBgmNotes, pattern.duration * 1000); console.log(`Started BGM: ${name}`);
                 };
             });
        }
        function stopCurrentBgm() { /* ... (same as before) ... */
             if (currentBgmInterval) { clearInterval(currentBgmInterval); currentBgmInterval = null; }
             bgmOscillators.forEach(osc => { try { osc.stop(audioContext.currentTime); } catch(e) { /* Ignore */ } }); bgmOscillators = [];
        }

        // --- Event Listeners Setup ---
        function setupEventListeners() {
            // Only setup once
            if (startCamBtn.onclick) return; // Basic check to prevent duplicate listeners

            startCamBtn.onclick = initCamera;
            startRecBtn.onclick = startRecording;
            stopRecBtn.onclick = stopRecording;

            // Background Controls
            bgSelect.onchange = updateBackground;
            bgColorPicker.oninput = updateBackground; // Use oninput for live color update
            bgUpload.onchange = handleBackgroundUpload;

             // Camera View Controls
            cameraScaleSlider.oninput = handleCameraScaleChange;
            resetViewBtn.onclick = resetCameraView;


            // Text/Shape Controls
            addTextBtn.onclick = addTextOverlay;
            clearGraphicsBtn.onclick = clearAllGraphics;
            shapeButtons.forEach(button => button.addEventListener('click', addShapeOverlay));

             // Audio Controls
             sfxButtons.forEach(button => {
                 button.addEventListener('click', (e) => {
                     const sfxType = e.currentTarget.getAttribute('data-sfx');
                     if (sfxSounds[sfxType]) sfxSounds[sfxType]();
                 });
             });
            bgmSelect.onchange = changeBgm;
            bgmVolume.oninput = updateBgmVolume;
        }

        // --- Recording Logic (no changes needed here) ---
        function startRecording() { /* ... (same as before) ... */
             if (!webcamStream || !pixiApp || !audioContext) { alert("Please start camera first."); return; }
             if (mediaRecorder && mediaRecorder.state === "recording") return;
             if (audioContext.state === 'suspended') { audioContext.resume(); }
             recordedChunks = []; downloadLink.style.display = 'none';
             const canvasStream = pixiCanvasElement.captureStream(30); const canvasVideoTrack = canvasStream.getVideoTracks()[0];
             const mixedAudioStream = destinationNode.stream; const mixedAudioTrack = mixedAudioStream.getAudioTracks()[0];
             if (!canvasVideoTrack) { alert("Could not capture video track."); return; }
             combinedStream = new MediaStream(); combinedStream.addTrack(canvasVideoTrack);
             if (mixedAudioTrack) { combinedStream.addTrack(mixedAudioTrack); } else { console.warn("Recording video only (no audio track)."); }
             let options = { mimeType: 'video/webm;codecs=vp9,opus' };
             if (!MediaRecorder.isTypeSupported(options.mimeType)) { options.mimeType = 'video/webm;codecs=vp8,opus'; }
             if (!MediaRecorder.isTypeSupported(options.mimeType)) { options.mimeType = 'video/webm'; }
             if (!MediaRecorder.isTypeSupported(options.mimeType)) { alert("WebM recording not supported."); return; }
             try { mediaRecorder = new MediaRecorder(combinedStream, options); } catch (e) { alert(`Error creating MediaRecorder: ${e.message}`); return; }
             mediaRecorder.ondataavailable = handleDataAvailable; mediaRecorder.onstop = handleStop;
             mediaRecorder.onerror = (event) => { console.error("MediaRecorder error:", event.error); alert(`MediaRecorder error: ${event.error.name}`); stopRecording(); };
             mediaRecorder.start(1000); console.log("Recording started.", mediaRecorder.mimeType);
             startRecBtn.disabled = true; stopRecBtn.disabled = false; startRecBtn.classList.add('recording'); startRecBtn.textContent = 'Recording...';
             changeBgm(); // Ensure BGM starts if selected
        }
        function handleDataAvailable(event) { /* ... (same as before) ... */ if (event.data.size > 0) { recordedChunks.push(event.data); } }
        function stopRecording() { /* ... (same as before) ... */
             if (mediaRecorder && mediaRecorder.state !== "inactive") { mediaRecorder.stop(); }
             stopCurrentBgm();
             startRecBtn.disabled = false; stopRecBtn.disabled = true; startRecBtn.classList.remove('recording'); startRecBtn.textContent = 'Start Recording';
        }
        function handleStop() { /* ... (same as before) ... */
             console.log("Recording stopped."); if (recordedChunks.length === 0) { alert("Recording produced no data."); return; }
             const blob = new Blob(recordedChunks, { type: mediaRecorder.mimeType || 'video/webm' });
             const url = URL.createObjectURL(blob); downloadLink.href = url;
             downloadLink.download = `recording-${new Date().toISOString().slice(0,19).replace(/[:T]/g,'-')}.webm`;
             downloadLink.style.display = 'inline-block'; console.log("Download ready.", `Size: ${(blob.size / 1024 / 1024).toFixed(2)} MB`);
        }

        // --- Drag and Drop Logic ---
        function onDragStart(event) {
            this.alpha = 0.8; // Make slightly transparent while dragging
            this.dragging = true;
            dragTarget = this; // Store the target being dragged

            // Bring the dragged item to the top *within its layer*
            // For graphicsContainer items:
            if (this.parent === graphicsContainer && graphicsContainer.children.length > 1) {
                graphicsContainer.removeChild(this);
                graphicsContainer.addChild(this);
            }
            // Video sprite is already in its own layer below graphics, so no need to reorder it globally

            event.stopPropagation(); // Prevent event bubbling
        }
        function onDragEnd() {
            if (this.dragging) {
                this.alpha = 1; // Restore opacity
                this.dragging = false;
                dragTarget = null;
            }
        }
        function onDragMove(event) {
            if (this.dragging) {
                const newPosition = event.data.getLocalPosition(this.parent);
                // Keep sprite within canvas bounds (optional, but good UX)
                // Adjust bounds based on scaled size if needed
                const bounds = this.getBounds(); // Current bounds
                const parentWidth = this.parent.width || pixiApp.screen.width;
                const parentHeight = this.parent.height || pixiApp.screen.height;

                 // Calculate proposed new position based on drag delta relative to anchor (0,0)
                this.x = newPosition.x;
                this.y = newPosition.y;

                 // Clamp position (simple clamping based on top-left corner)
                 this.x = Math.max(0, Math.min(this.x, parentWidth - bounds.width));
                 this.y = Math.max(0, Math.min(this.y, parentHeight - bounds.height));

            }
        }

        // --- Overlay/View Functions ---
        function addTextOverlay() { /* ... (same as before - uses drag handlers) ... */
            if (!pixiApp || !textInput.value.trim()) return;
            const textStyle = new PIXI.TextStyle({ fontFamily: 'Arial', fontSize: parseInt(textSize.value) || 24, fill: textColor.value || "#FFFF00", stroke: '#000000', strokeThickness: 4, dropShadow: true, dropShadowColor: '#000000', dropShadowBlur: 4, dropShadowDistance: 2, wordWrap: true, wordWrapWidth: pixiApp.screen.width * 0.8 });
            const text = new PIXI.Text(textInput.value, textStyle);
            text.anchor.set(0.5); text.x = pixiApp.screen.width / 2; text.y = 60;
            text.interactive = true; text.buttonMode = true; text.cursor = 'move';
            text.on('pointerdown', onDragStart).on('pointerup', onDragEnd).on('pointerupoutside', onDragEnd).on('pointermove', onDragMove);
            graphicsContainer.addChild(text);
        }
        function addShapeOverlay(event) { /* ... (same as before - uses drag handlers) ... */
            if (!pixiApp) return;
            const button = event.currentTarget; const shapeType = button.getAttribute('data-shape'); const size = parseInt(shapeSize.value) || 50; const color = parseInt(shapeColor.value.replace('#', '0x')) || 0xff0000;
            let shape = new PIXI.Graphics(); shape.beginFill(color, 0.8); shape.lineStyle(2, 0x000000, 0.8);
            switch (shapeType) {
                case 'circle': shape.drawCircle(0, 0, size / 2); break; case 'rectangle': shape.drawRect(-size/2, -size/2, size, size); break;
                case 'triangle': shape.moveTo(0, -size/2); shape.lineTo(size/2, size/2); shape.lineTo(-size/2, size/2); shape.closePath(); break;
                case 'star': shape.drawStar(0, 0, 5, size / 2, size / 4, 0); break; default: shape = null;
            } shape.endFill();
            if (shape) {
                shape.x = Math.random() * (pixiApp.screen.width * 0.8) + pixiApp.screen.width * 0.1; shape.y = Math.random() * (pixiApp.screen.height * 0.6) + pixiApp.screen.height * 0.2;
                shape.interactive = true; shape.buttonMode = true; shape.cursor = 'move';
                shape.on('pointerdown', onDragStart).on('pointerup', onDragEnd).on('pointerupoutside', onDragEnd).on('pointermove', onDragMove);
                graphicsContainer.addChild(shape);
            }
        }
        function clearAllGraphics() { /* ... (same as before - only clears graphicsContainer) ... */
            if (graphicsContainer) {
                 while(graphicsContainer.children.length > 0) {
                     const child = graphicsContainer.removeChildAt(0);
                     child.destroy({ children: true });
                 } console.log("Cleared text & shapes.");
            }
        }

        function handleCameraScaleChange() {
            if (!videoSprite || !pixiApp) return;
            const scale = parseFloat(cameraScaleSlider.value);
            videoSprite.scale.set(scale); // Uniform scaling
            cameraScaleValueSpan.textContent = `${scale.toFixed(1)}x`;

             // Optional: Clamp position after scaling to keep it within bounds
             const bounds = videoSprite.getBounds();
             const parentWidth = pixiApp.screen.width;
             const parentHeight = pixiApp.screen.height;
             videoSprite.x = Math.max(0, Math.min(videoSprite.x, parentWidth - bounds.width));
             videoSprite.y = Math.max(0, Math.min(videoSprite.y, parentHeight - bounds.height));
        }

        function resetCameraView() {
             if (!videoSprite || !pixiApp) return;
             // Reset scale
             cameraScaleSlider.value = 1.0;
             handleCameraScaleChange(); // Update scale and text

             // Reset position (center it?)
             videoSprite.x = (pixiApp.screen.width - videoSprite.width) / 2;
             videoSprite.y = (pixiApp.screen.height - videoSprite.height) / 2;

             // Clamp position just in case (especially if scale was > 1)
              const bounds = videoSprite.getBounds();
              const parentWidth = pixiApp.screen.width;
              const parentHeight = pixiApp.screen.height;
              videoSprite.x = Math.max(0, Math.min(videoSprite.x, parentWidth - bounds.width));
              videoSprite.y = Math.max(0, Math.min(videoSprite.y, parentHeight - bounds.height));
             console.log("Camera view reset.");
        }

        // --- Background Functions ---
        function updateBackground() {
            if (!pixiApp || !backgroundSprite) return;

            const selection = bgSelect.value;

            // Hide/show color picker based on selection
            bgColorPicker.style.display = (selection === 'color') ? 'inline-block' : 'none';

            if (selection === 'color') {
                const colorValue = PIXI.utils.string2hex(bgColorPicker.value);
                pixiApp.renderer.backgroundColor = colorValue; // Set renderer background
                pixiApp.renderer.backgroundAlpha = 1; // Ensure it's opaque
                backgroundSprite.texture = PIXI.Texture.EMPTY; // Clear sprite texture
                console.log("Background set to color:", bgColorPicker.value);
            } else {
                // Use an image background
                pixiApp.renderer.backgroundColor = 0x000000; // Set fallback bg color
                pixiApp.renderer.backgroundAlpha = 0; // Make renderer transparent

                const imageUrl = PRESET_BACKGROUNDS[selection];
                if (imageUrl) {
                    // Check if texture is already loaded to avoid flicker
                    let texture = PIXI.Loader.shared.resources[imageUrl]?.texture;
                    if (texture) {
                         backgroundSprite.texture = texture;
                         console.log("Using cached background:", selection);
                         adjustBackgroundSize();
                    } else {
                         // Load texture if not cached
                         backgroundSprite.texture = PIXI.Texture.WHITE; // Placeholder while loading
                         backgroundSprite.tint = 0xAAAAAA;
                         PIXI.Loader.shared.add(imageUrl).load((loader, resources) => {
                              if (resources[imageUrl] && resources[imageUrl].texture) {
                                  // Check if selection hasn't changed while loading
                                  if (bgSelect.value === selection) {
                                       backgroundSprite.texture = resources[imageUrl].texture;
                                       backgroundSprite.tint = 0xFFFFFF; // Reset tint
                                       console.log("Loaded background:", selection);
                                       adjustBackgroundSize();
                                  }
                              } else {
                                  console.error("Failed to load background resource:", imageUrl);
                                  // Revert to color if load fails?
                                  if (bgSelect.value === selection) {
                                       bgSelect.value = 'color';
                                       updateBackground();
                                  }
                              }
                         });
                    }
                } else {
                     console.warn("Preset background URL not found for:", selection);
                     backgroundSprite.texture = PIXI.Texture.EMPTY; // Clear texture if invalid
                }
            }
        }

        function handleBackgroundUpload(event) {
            const file = event.target.files[0];
            if (file && file.type.startsWith('image/')) {
                const reader = new FileReader();
                reader.onload = (e) => {
                    const imageUrl = e.target.result;
                    // Use unique ID for uploaded texture cache? or just load directly
                    const texture = PIXI.Texture.from(imageUrl); // PIXI handles DataURL

                    // Make sure renderer is transparent for image backgrounds
                    pixiApp.renderer.backgroundColor = 0x000000;
                    pixiApp.renderer.backgroundAlpha = 0;

                    backgroundSprite.texture = texture;
                    console.log("Uploaded background set.");
                    adjustBackgroundSize();

                     // Select "Upload" visually if we add an option for it, or just show the image
                     // Maybe disable preset dropdown after upload? User choice.
                     // bgSelect.value = 'upload-placeholder'; // If you add such an option
                     // For now, just override preset selection
                     bgSelect.value = 'color'; // Change dropdown to avoid confusion
                     bgColorPicker.style.display = 'none';
                }
                reader.readAsDataURL(file);
            } else if (file) {
                 alert("Please select a valid image file.");
            }
             // Clear the input value so the same file can be selected again if needed
             event.target.value = null;
        }

         function adjustBackgroundSize() {
             // Scale background to cover canvas while maintaining aspect ratio
             if (!backgroundSprite || !backgroundSprite.texture || backgroundSprite.texture === PIXI.Texture.EMPTY) return;

             const bgTexture = backgroundSprite.texture;
             const canvasWidth = pixiApp.screen.width;
             const canvasHeight = pixiApp.screen.height;
             const canvasRatio = canvasWidth / canvasHeight;
             const bgRatio = bgTexture.width / bgTexture.height;

             if (canvasRatio > bgRatio) {
                 // Canvas is wider than background aspect ratio
                 backgroundSprite.width = canvasWidth;
                 backgroundSprite.height = canvasWidth / bgRatio;
             } else {
                 // Canvas is taller or same aspect ratio
                 backgroundSprite.height = canvasHeight;
                 backgroundSprite.width = canvasHeight * bgRatio;
             }
             // Center the background image
             backgroundSprite.x = (canvasWidth - backgroundSprite.width) / 2;
             backgroundSprite.y = (canvasHeight - backgroundSprite.height) / 2;
         }


        // --- Audio Control Functions (no changes needed here) ---
        function changeBgm() { /* ... (same as before) ... */ stopCurrentBgm(); const sel = bgmSelect.value; if (sel !== 'none' && bgmSounds[sel]) { if (audioContext.state === 'suspended') audioContext.resume(); if (mediaRecorder && mediaRecorder.state === 'recording') bgmSounds[sel](); else console.log("BGM selected, starts on record."); } }
        function updateBgmVolume() { /* ... (same as before) ... */ if (bgmGainNode) { bgmGainNode.gain.setTargetAtTime(parseFloat(bgmVolume.value), audioContext.currentTime, 0.015); } }

        // --- Start the App ---
         document.addEventListener('DOMContentLoaded', () => {
            // Setup listeners but don't init camera until button click
            setupEventListeners();
            // Initial UI setup
            bgColorPicker.style.display = 'inline-block'; // Show color picker initially
             console.log("DOM loaded. Ready for camera start.");
        });


        // --- Cleanup ---
        window.onbeforeunload = () => {
             webcamStream?.getTracks().forEach(track => track.stop());
             combinedStream?.getTracks().forEach(track => track.stop());
             if (mediaRecorder && mediaRecorder.state === "recording") mediaRecorder.stop();
             stopCurrentBgm();
             audioContext?.close().catch(e => console.warn("Error closing AudioContext:", e));
             // IMPORTANT: Fully destroy Pixi app and release resources
             if (pixiApp) {
                pixiApp.destroy(true, { children: true, texture: true, baseTexture: true });
                pixiApp = null; // Ensure reference is cleared
             }
        };

    </script>

</body>
</html>