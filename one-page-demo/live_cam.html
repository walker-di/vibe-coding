<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC Pixi.js Recorder V3 (Masking)</title>
    <!-- Using PixiJS v6.5.10 as used in development -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/6.5.10/browser/pixi.min.js"></script>
    <style>
        /* Base styles */
        body {
            font-family: sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            background-color: #f0f0f0;
            margin: 0;
        }
        .container {
            max-width: 1200px;
            width: 95%;
            margin: 0 auto;
        }
        .video-container {
            position: relative;
            margin-bottom: 20px;
            width: 100%;
            max-width: 640px; /* Limit max width */
            margin-left: auto;
            margin-right: auto;
            aspect-ratio: 640 / 480; /* Default aspect ratio */
            background-color: #cccccc; /* Default light grey background */
            border: 1px solid #999;
            overflow: hidden; /* Hide parts of video/bg if they go outside */
        }
        #webcamVideo { display: none; } /* Hidden source video */
        #pixiCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: auto; /* Allow interaction */
            cursor: default; /* Default cursor */
        }
        .controls, .toolbar {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-bottom: 20px;
            width: 100%;
            max-width: 800px; /* Limit control width */
            margin-left: auto;
            margin-right: auto;
        }
         .toolbar {
            flex-direction: column; /* Stack toolbar sections */
            background-color: #fff;
            border-radius: 8px;
            padding: 15px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .toolbar-section {
            margin-bottom: 15px;
            width: 100%;
        }
         h1, h2 {
             text-align: center;
             color: #333;
             margin-top: 0;
             margin-bottom: 15px;
         }
         h2 {
             font-size: 18px;
             text-align: left;
             border-bottom: 1px solid #eee;
             padding-bottom: 5px;
             margin-bottom: 10px;
         }
         button {
            background-color: #4285f4;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
            transition: background-color 0.2s ease;
        }
        button:hover:not(:disabled) { background-color: #3367d6; }
        button:disabled { background-color: #ccc; cursor: not-allowed; }

        /* Control groups styling */
        .control-group {
             display: flex;
             flex-wrap: wrap;
             align-items: center;
             gap: 10px;
             margin-bottom: 10px;
        }
         label { margin-right: 5px; font-weight: bold; font-size: 14px; }
         input[type="text"], input[type="number"], select, input[type="file"] {
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 14px;
         }
         input[type="color"].color-picker {
            min-width: 40px; /* Ensure minimum width */
            height: 36px;
            padding: 2px;
            border: 1px solid #ddd;
            border-radius: 4px;
            cursor: pointer;
         }
         input[type="range"] {
             cursor: pointer;
             flex-grow: 1; /* Allow slider to take up space */
             min-width: 150px;
         }
        .shape-btn {
            width: 40px;
            height: 40px;
            margin-right: 5px;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            padding: 0;
            background-color: #e0e0e0;
            color: #333;
        }
         .shape-btn:hover:not(:disabled) { background-color: #bdbdbd; }
         .shape-preview { font-size: 18px; }

        .sfx-button {
            background-color: #ff7043;
            min-width: 40px; /* Smaller SFX buttons */
             padding: 8px; /* Adjust padding */
             font-size: 18px; /* Make emoji bigger */
        }
        .sfx-button:hover:not(:disabled) { background-color: #f4511e; }

        #downloadLink {
            display: none;
            margin-top: 15px;
            padding: 10px 20px;
            background-color: #4CAF50;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            text-align: center;
        }
        .recording {
            background-color: #f44336 !important;
            color: white;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
             0% { box-shadow: 0 0 0 0 rgba(244, 67, 54, 0.7); }
             70% { box-shadow: 0 0 0 10px rgba(244, 67, 54, 0); }
             100% { box-shadow: 0 0 0 0 rgba(244, 67, 54, 0); }
        }

        /* Style for file input */
        input[type="file"] {
            border: none;
            padding: 0;
            flex-grow: 1;
            min-width: 100px;
        }
        input[type="file"]::file-selector-button {
             background-color: #6c757d;
             color: white;
             border: none;
             padding: 8px 12px;
             border-radius: 4px;
             cursor: pointer;
             margin-right: 10px;
             transition: background-color 0.2s ease;
        }
        input[type="file"]::file-selector-button:hover {
             background-color: #5a6268;
        }
        small { /* Style for hint text */
             display: block;
             width: 100%;
             margin-top: -5px;
             margin-bottom: 5px;
             color: #666;
             font-size: 12px;
        }

    </style>
</head>
<body>
    <div class="container">
        <h1>WebRTC Pixi.js Recorder V3</h1>

        <!-- Hidden video element for webcam stream -->
        <video id="webcamVideo" playsinline autoplay muted></video>

        <!-- Container for the PixiJS Canvas -->
        <div class="video-container">
            <canvas id="pixiCanvas"></canvas>
        </div>

        <!-- Main Recording Controls -->
        <div class="controls">
            <button id="startCamBtn">Start Camera</button>
            <button id="startRecBtn" disabled>Start Recording</button>
            <button id="stopRecBtn" disabled>Stop Recording</button>
            <a id="downloadLink" download="recording.webm">Download Recording</a>
        </div>

        <!-- Toolbar for editing controls -->
        <div class="toolbar">
            <!-- Background Controls -->
            <div class="toolbar-section">
                <h2>Background</h2>
                <div class="control-group">
                    <label for="bgSelect">Preset:</label>
                    <select id="bgSelect">
                        <option value="color">Color</option>
                        <option value="office.jpg">Office</option> <!-- Replace with actual URLs -->
                        <option value="space.jpg">Space</option> <!-- Replace with actual URLs -->
                        <option value="gradient.png">Gradient</option> <!-- Replace with actual URLs -->
                    </select>
                    <input type="color" id="bgColorPicker" class="color-picker" value="#cccccc" title="Background Color">
                     <label for="bgUpload" style="margin-left: auto;">Upload:</label>
                    <input type="file" id="bgUpload" accept="image/*">
                </div>
            </div>

             <!-- Camera View Controls -->
            <div class="toolbar-section">
                <h2>Camera View</h2>
                <div class="control-group">
                     <label for="cameraScale">Scale:</label>
                     <input type="range" id="cameraScale" min="0.2" max="2.0" step="0.05" value="1.0">
                     <span id="cameraScaleValue">1.0x</span>

                     <label for="cameraMaskShape" style="margin-left: 15px;">Mask:</label>
                     <select id="cameraMaskShape">
                         <option value="none">None</option>
                         <option value="circle">Circle</option>
                         <option value="ellipse">Ellipse</option>
                         <option value="rounded_rect">Rounded Rect</option>
                         <option value="star">Star (5 points)</option>
                     </select>

                     <button id="resetViewBtn" style="margin-left: auto;">Reset View</button>
                </div>
                 <small>Click and drag the camera view to reposition it.</small>
            </div>

            <!-- Text & Shapes Controls -->
            <div class="toolbar-section">
                <h2>Text & Shapes</h2>
                <div class="control-group">
                    <label>Text:</label>
                    <input type="text" id="textInput" placeholder="Enter text">
                    <input type="number" id="textSize" min="12" max="72" value="24" title="Text Size" style="width: 60px;">
                    <input type="color" id="textColor" class="color-picker" value="#FFFF00" title="Text Color">
                    <button id="addTextBtn" title="Add Text">Add Text</button>
                 </div>
                 <div class="control-group">
                    <label>Shapes:</label>
                    <button class="shape-btn" data-shape="circle" title="Circle"><span class="shape-preview">⚪</span></button>
                    <button class="shape-btn" data-shape="rectangle" title="Rectangle"><span class="shape-preview">▢</span></button>
                    <button class="shape-btn" data-shape="triangle" title="Triangle"><span class="shape-preview">△</span></button>
                    <button class="shape-btn" data-shape="star" title="Star"><span class="shape-preview">★</span></button>
                    <input type="color" id="shapeColor" class="color-picker" value="#ff0000" title="Shape Color">
                    <input type="number" id="shapeSize" min="10" max="200" value="50" title="Shape Size" style="width: 60px;">
                     <button id="clearGraphicsBtn" style="margin-left: auto;" title="Clear All Text & Shapes">Clear Graphics</button>
                 </div>
                 <small>Click and drag text/shapes to reposition.</small>
            </div>

            <!-- Audio Controls -->
            <div class="toolbar-section">
                <h2>Audio</h2>
                 <div class="control-group">
                     <label>SFX:</label>
                     <button class="sfx-button" data-sfx="applause" title="Applause">👏</button>
                     <button class="sfx-button" data-sfx="drumroll" title="Drumroll">🥁</button>
                     <button class="sfx-button" data-sfx="bell" title="Bell">🔔</button>
                     <button class="sfx-button" data-sfx="laugh" title="Laugh">😄</button>
                 </div>
                 <div class="control-group">
                    <label for="bgmSelect">BGM:</label>
                    <select id="bgmSelect">
                        <option value="none">None</option>
                        <option value="upbeat">Upbeat</option>
                        <option value="relaxed">Relaxed</option>
                        <option value="dramatic">Dramatic</option>
                    </select>
                    <label for="bgmVolume" style="margin-left: auto;">Vol:</label>
                    <input type="range" id="bgmVolume" min="0" max="1" step="0.05" value="0.3">
                 </div>
            </div>
        </div> <!-- End Toolbar -->
    </div> <!-- End Container -->

    <script>
        // --- Configuration ---
        const CANVAS_WIDTH = 640;
        const CANVAS_HEIGHT = 480;
        // IMPORTANT: Replace placeholder URLs with your actual, accessible image URLs!
        // Ensure CORS headers are set if hosting images elsewhere.
        const PRESET_BACKGROUNDS = {
            'office.jpg': 'https://via.placeholder.com/640x480/aabbcc/888888?text=Office+BG', // Replace!
            'space.jpg': 'https://via.placeholder.com/640x480/000033/ffffff?text=Space+BG',   // Replace!
            'gradient.png': 'https://via.placeholder.com/640x480/ffccaa/aa66cc?text=Gradient+BG' // Replace!
        };

        // --- Global Variables ---
        let pixiApp = null;
        let webcamVideoElement = document.getElementById('webcamVideo');
        let pixiCanvasElement = document.getElementById('pixiCanvas');
        let backgroundSprite = null;
        let videoSprite = null;
        let cameraMaskGraphics = null; // Graphics object for the camera mask
        let graphicsContainer = null; // Container for text/shapes overlays

        let mediaRecorder = null;
        let recordedChunks = [];
        let combinedStream = null;
        let webcamStream = null;

        // Audio related
        let audioContext = null;
        let micSourceNode = null, micGainNode = null;
        let sfxGainNode = null;
        let bgmGainNode = null;
        let destinationNode = null; // Captures mixed audio
        let sfxSounds = {};
        let bgmSounds = {};
        let currentBgmInterval = null;
        let bgmOscillators = [];

        // UI Elements
        const startCamBtn = document.getElementById('startCamBtn');
        const startRecBtn = document.getElementById('startRecBtn');
        const stopRecBtn = document.getElementById('stopRecBtn');
        const downloadLink = document.getElementById('downloadLink');
        // Background
        const bgSelect = document.getElementById('bgSelect');
        const bgColorPicker = document.getElementById('bgColorPicker');
        const bgUpload = document.getElementById('bgUpload');
        // Camera View
        const cameraScaleSlider = document.getElementById('cameraScale');
        const cameraScaleValueSpan = document.getElementById('cameraScaleValue');
        const cameraMaskShapeSelect = document.getElementById('cameraMaskShape');
        const resetViewBtn = document.getElementById('resetViewBtn');
        // Text/Shapes
        const addTextBtn = document.getElementById('addTextBtn');
        const textInput = document.getElementById('textInput');
        const textSize = document.getElementById('textSize');
        const textColor = document.getElementById('textColor');
        const shapeButtons = document.querySelectorAll('.shape-btn');
        const shapeColor = document.getElementById('shapeColor');
        const shapeSize = document.getElementById('shapeSize');
        const clearGraphicsBtn = document.getElementById('clearGraphicsBtn');
        // Audio
        const sfxButtons = document.querySelectorAll('.sfx-button');
        const bgmSelect = document.getElementById('bgmSelect');
        const bgmVolume = document.getElementById('bgmVolume');

        // Drag state
        let dragTarget = null; // Holds the Pixi object being dragged

        // --- Initialization ---
        async function initCamera() {
             if (webcamStream) { // Prevent re-initialization
                 console.log("Camera already initialized.");
                 return;
             }
             startCamBtn.disabled = true; // Disable button during init
             startCamBtn.textContent = 'Initializing...';

             try {
                webcamStream = await navigator.mediaDevices.getUserMedia({
                    video: { width: CANVAS_WIDTH, height: CANVAS_HEIGHT }, // Request preferred size
                    audio: true
                });
                webcamVideoElement.srcObject = webcamStream;
                await webcamVideoElement.play(); // Ensure video starts playing

                const actualWidth = webcamVideoElement.videoWidth || CANVAS_WIDTH;
                const actualHeight = webcamVideoElement.videoHeight || CANVAS_HEIGHT;

                // Adjust container aspect ratio to match video
                const videoContainer = document.querySelector('.video-container');
                videoContainer.style.aspectRatio = `${actualWidth} / ${actualHeight}`;

                if (!pixiApp) {
                    setupPixi(actualWidth, actualHeight);
                } else { // Resize existing Pixi app if camera restarts with different dimensions
                    pixiApp.renderer.resize(actualWidth, actualHeight);
                    backgroundSprite.width = actualWidth;
                    backgroundSprite.height = actualHeight;
                    resetCameraView(); // Reset view on resize
                }

                if (!audioContext) setupAudio(); // Setup audio context if not already done
                setupEventListeners(); // Ensure listeners are attached

                startRecBtn.disabled = false; // Enable recording button
                startCamBtn.textContent = 'Camera Active'; // Update button text
                console.log("Camera and Mic initialized successfully.");

             } catch (err) {
                 console.error("Error accessing media devices.", err);
                 alert(`Could not access camera/microphone: ${err.name}\n${err.message}\nPlease check permissions and ensure devices are available.`);
                 startCamBtn.disabled = false; // Re-enable button on failure
                 startCamBtn.textContent = 'Start Camera';
             }
        }

        // --- Pixi.js Setup ---
        function setupPixi(width, height) {
            pixiApp = new PIXI.Application({
                view: pixiCanvasElement,
                width: width,
                height: height,
                resolution: window.devicePixelRatio || 1,
                autoDensity: true,
                antialias: true,
                transparent: true // Required for background color/image layers
            });

            // Layer 0: Background
            backgroundSprite = new PIXI.Sprite(); // Initially empty
            backgroundSprite.width = width; backgroundSprite.height = height;
            backgroundSprite.anchor.set(0);
            pixiApp.stage.addChildAt(backgroundSprite, 0);
            updateBackground(); // Set initial background

            // Layer 1: Video Sprite + Mask
            const videoTexture = PIXI.Texture.from(webcamVideoElement);
            videoSprite = new PIXI.Sprite(videoTexture);
            videoSprite.width = videoTexture.width || width; // Use texture dimensions if available
            videoSprite.height = videoTexture.height || height;
            videoSprite.anchor.set(0); // Top-left anchor simplifies coordinate math
            videoSprite.x = (width - videoSprite.width) / 2; // Center initially
            videoSprite.y = (height - videoSprite.height) / 2;

            // Create mask graphics as a CHILD of the video sprite
            cameraMaskGraphics = new PIXI.Graphics();
            videoSprite.addChild(cameraMaskGraphics); // Mask transforms with video
            videoSprite.mask = null; // No mask initially

            // Make video draggable
            videoSprite.interactive = true;
            videoSprite.buttonMode = true;
            videoSprite.cursor = 'move';
            videoSprite
                .on('pointerdown', onDragStart)
                .on('pointerup', onDragEnd)
                .on('pointerupoutside', onDragEnd)
                .on('pointermove', onDragMove);
            pixiApp.stage.addChildAt(videoSprite, 1); // Add video above background

            // Layer 2: Graphics Overlays (Text, Shapes)
             graphicsContainer = new PIXI.Container();
             graphicsContainer.interactive = true; // Allow interaction for children
             pixiApp.stage.addChildAt(graphicsContainer, 2); // Add graphics above video

            // Ticker to update video texture (critical for live view)
            pixiApp.ticker.add(() => {
                if (webcamVideoElement.readyState >= webcamVideoElement.HAVE_CURRENT_DATA) {
                     try {
                         videoTexture.update();
                     } catch (e) { // Handle potential context loss errors
                         console.warn("Error updating video texture (WebGL context lost?)", e);
                     }
                }
            });

            console.log("PixiJS setup complete.");
            applyCameraMask(); // Apply initial mask state ('none')
        }

        // --- Web Audio API Setup ---
        function setupAudio() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            // Create node to capture mixed audio for recording
            destinationNode = audioContext.createMediaStreamDestination();

            // 1. Microphone Input
            if (webcamStream && webcamStream.getAudioTracks().length > 0) {
                micSourceNode = audioContext.createMediaStreamSource(webcamStream);
                micGainNode = audioContext.createGain(); micGainNode.gain.value = 1.0; // Mic volume
                micSourceNode.connect(micGainNode)
                             .connect(destinationNode); // Connect to recording destination
                micGainNode.connect(audioContext.destination); // Also connect to output for live preview (optional)
                console.log("Microphone connected to audio graph.");
            } else { console.warn("No microphone audio track found in stream."); }

            // 2. SFX Gain Node (controls overall SFX volume)
            sfxGainNode = audioContext.createGain(); sfxGainNode.gain.value = 0.6; // SFX volume
            sfxGainNode.connect(destinationNode); // Connect to recording destination
            sfxGainNode.connect(audioContext.destination); // Connect to output for live preview
            initSfxSounds(); // Create the SFX generator functions
            console.log("SFX node ready.");

            // 3. BGM Gain Node (controls overall BGM volume)
            bgmGainNode = audioContext.createGain(); bgmGainNode.gain.value = parseFloat(bgmVolume.value); // Initial BGM volume
            bgmGainNode.connect(destinationNode); // Connect to recording destination
            bgmGainNode.connect(audioContext.destination); // Connect to output for live preview
            initBgmSounds(); // Create the BGM generator functions
            console.log("BGM node ready.");
        }

        // --- Synthesized Audio Generation ---
        function initSfxSounds() {
             const sfxData = { applause: [0.3, 0.7, 0.2, 0.4, 0.6, 0.8, 0.4, 0.6, 0.2, 0.4], drumroll: [0.2, 0.6, 0.2, 0.6, 0.2, 0.6, 0.2, 0.8, 0.9, 1.0], bell: [1.0, 0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0], laugh: [0.3, 0.5, 0.7, 0.5, 0.3, 0.5, 0.7, 0.5, 0.3] };
             Object.keys(sfxData).forEach(name => {
                 sfxSounds[name] = () => {
                     if (!audioContext) return;
                     // Resume context if suspended (browser interaction needed first time)
                     if (audioContext.state === 'suspended') { audioContext.resume().catch(e => console.error("Audio resume failed", e)); }
                     const now = audioContext.currentTime;
                     const osc = audioContext.createOscillator();
                     const gainNode = audioContext.createGain(); // Temporary gain for envelope

                     osc.type = name === 'bell' ? 'sine' : (name === 'drumroll' ? 'noise' : 'square');
                     if (osc.type !== 'noise') { // Set frequency for non-noise types
                         osc.frequency.value = name === 'bell' ? 880 : (name === 'laugh' ? 440 : 110);
                     }

                     osc.connect(gainNode);
                     gainNode.connect(sfxGainNode); // Connect envelope gain to main SFX gain
                     osc.start(now);

                     // Simple amplitude envelope
                     const duration = name === 'drumroll' ? 0.05 : 0.1;
                     const pattern = sfxData[name];
                     gainNode.gain.setValueAtTime(0, now); // Start silent
                     pattern.forEach((value, i) => { // Apply gain changes over time
                         gainNode.gain.linearRampToValueAtTime(value * 0.5, now + (i + 0.5) * duration);
                     });
                     gainNode.gain.setValueAtTime(pattern[pattern.length - 1] * 0.5, now + pattern.length * duration); // Hold last value
                     gainNode.gain.linearRampToValueAtTime(0, now + pattern.length * duration + 0.1); // Fade out

                     osc.stop(now + pattern.length * duration + 0.15); // Stop oscillator after fade out
                 };
             });
        }
        function initBgmSounds() {
             const bgmPatterns = { upbeat: { notes: [440, 0, 493.88, 0, 523.25, 587.33, 659.25, 523.25], duration: 0.15, type: 'square' }, relaxed: { notes: [261.63, 0, 329.63, 0, 392, 0, 329.63, 0], duration: 0.4, type: 'sine' }, dramatic: { notes: [130.81, 146.83, 0, 130.81, 0, 98, 123.47, 98], duration: 0.3, type: 'sawtooth' } }; // 0 represents a rest
             Object.keys(bgmPatterns).forEach(name => {
                 const pattern = bgmPatterns[name];
                 bgmSounds[name] = () => {
                     stopCurrentBgm(); // Stop previous BGM
                     if (!audioContext) return;
                     if (audioContext.state === 'suspended') { audioContext.resume().catch(e => console.error("Audio resume failed", e)); }

                     let noteIndex = 0;
                     bgmOscillators = []; // Clear previous oscillators

                     // Function to play the sequence of notes
                     const playBgmNotes = () => {
                         if (!currentBgmInterval) return; // Stop if interval was cleared elsewhere
                         const now = audioContext.currentTime;
                         const noteFrequency = pattern.notes[noteIndex % pattern.notes.length];

                         if (noteFrequency > 0) { // Only play if it's not a rest (0)
                             const osc = audioContext.createOscillator();
                             const gain = audioContext.createGain(); // Gain for this note's envelope

                             osc.type = pattern.type;
                             osc.frequency.setValueAtTime(noteFrequency, now);
                             // Simple note envelope (quick attack, short decay)
                             gain.gain.setValueAtTime(0, now);
                             gain.gain.linearRampToValueAtTime(1.0, now + 0.02); // Attack
                             gain.gain.setValueAtTime(1.0, now + pattern.duration * 0.8); // Sustain
                             gain.gain.linearRampToValueAtTime(0, now + pattern.duration); // Decay/Release

                             osc.connect(gain);
                             gain.connect(bgmGainNode); // Connect note to main BGM gain

                             osc.start(now);
                             osc.stop(now + pattern.duration); // Stop note after its duration
                             bgmOscillators.push(osc); // Track oscillator to stop it forcefully if needed
                         }
                         noteIndex++;
                     };
                     playBgmNotes(); // Play the first note immediately
                     currentBgmInterval = setInterval(playBgmNotes, pattern.duration * 1000); // Schedule subsequent notes
                     console.log(`Started BGM: ${name}`);
                 };
             });
        }
        function stopCurrentBgm() {
             if (currentBgmInterval) {
                 clearInterval(currentBgmInterval);
                 currentBgmInterval = null;
                 console.log("Stopped BGM interval.");
             }
             // Force stop any lingering oscillators from the previous BGM loop
             bgmOscillators.forEach(osc => {
                 try { osc.stop(audioContext.currentTime); } catch(e) { /* Ignore errors if already stopped */ }
             });
             bgmOscillators = []; // Clear the tracking array
        }

        // --- Event Listeners Setup ---
        function setupEventListeners() {
            // Prevent adding listeners multiple times
            if (startCamBtn.dataset.listenersAttached) return;

            startCamBtn.onclick = initCamera;
            startRecBtn.onclick = startRecording;
            stopRecBtn.onclick = stopRecording;

            // Background Controls
            bgSelect.onchange = updateBackground;
            bgColorPicker.oninput = updateBackground; // Live color update
            bgUpload.onchange = handleBackgroundUpload;

            // Camera View Controls
            cameraScaleSlider.oninput = handleCameraScaleChange;
            cameraMaskShapeSelect.onchange = applyCameraMask; // Listener for mask dropdown
            resetViewBtn.onclick = resetCameraView;

            // Text/Shape Controls
            addTextBtn.onclick = addTextOverlay;
            clearGraphicsBtn.onclick = clearAllGraphics;
            shapeButtons.forEach(button => button.addEventListener('click', addShapeOverlay));

             // Audio Controls
             sfxButtons.forEach(button => {
                 button.addEventListener('click', (e) => {
                     const sfxType = e.currentTarget.getAttribute('data-sfx');
                     if (sfxSounds[sfxType]) sfxSounds[sfxType](); // Play the correct SFX function
                 });
             });
            bgmSelect.onchange = changeBgm;
            bgmVolume.oninput = updateBgmVolume; // Live volume update

            startCamBtn.dataset.listenersAttached = 'true'; // Mark as attached
            console.log("Event listeners attached.");
        }

        // --- Recording Logic ---
        function startRecording() {
             if (!webcamStream || !pixiApp || !audioContext) {
                 alert("Please start the camera first using the 'Start Camera' button.");
                 return;
             }
             if (mediaRecorder && mediaRecorder.state === "recording") {
                 console.warn("Already recording.");
                 return;
             }
             // Ensure audio context is running (might be suspended initially)
             if (audioContext.state === 'suspended') { audioContext.resume().catch(e=>console.error("Audio resume failed", e)); }

            recordedChunks = []; // Reset recorded data
            downloadLink.style.display = 'none'; // Hide previous download link

            // 1. Get Video Stream from Pixi Canvas
            // Ensure Pixi renders a frame right before capture if needed (usually ticker is enough)
            const canvasStream = pixiCanvasElement.captureStream(30); // Capture at 30 FPS
            const canvasVideoTrack = canvasStream.getVideoTracks()[0];

            // 2. Get Mixed Audio Stream from our Destination Node
            const mixedAudioStream = destinationNode.stream;
            const mixedAudioTrack = mixedAudioStream.getAudioTracks()[0];

            // 3. Combine Video and Audio Tracks
            if (!canvasVideoTrack) {
                 alert("Fatal: Could not capture video track from the canvas.");
                 return;
            }
            combinedStream = new MediaStream();
            combinedStream.addTrack(canvasVideoTrack);
            if (mixedAudioTrack) {
                 combinedStream.addTrack(mixedAudioTrack);
                 console.log("Recording canvas video and mixed audio (Mic/SFX/BGM).");
            } else {
                console.warn("Recording canvas video only (no mixed audio track available).");
            }

            // 4. Create MediaRecorder Instance
            // Try preferred codecs first, fall back to browser default if needed
             let options = { mimeType: 'video/webm;codecs=vp9,opus' };
             if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                 console.warn(`${options.mimeType} not supported, trying vp8,opus`);
                 options.mimeType = 'video/webm;codecs=vp8,opus';
             }
             if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                 console.warn(`${options.mimeType} not supported, trying video/webm`);
                 options.mimeType = 'video/webm'; // Browser default webm
             }
             if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                 console.error(`Fatal: video/webm MIME type is not supported by this browser.`);
                  alert("Sorry, your browser doesn't support the required WebM recording format.");
                 return;
             }
             // Optional: Specify audio/video bitrate
             // options.audioBitsPerSecond = 128000; // e.g., 128 kbps
             // options.videoBitsPerSecond = 2500000; // e.g., 2.5 Mbps

            try {
                mediaRecorder = new MediaRecorder(combinedStream, options);
            } catch (e) {
                 console.error("Exception creating MediaRecorder:", e);
                 alert(`Error setting up recorder: ${e.message}\nMIME type attempted: ${options.mimeType}`);
                 return;
            }
            console.log("MediaRecorder created with MIME type:", mediaRecorder.mimeType);

            // 5. Setup Event Handlers for MediaRecorder
            mediaRecorder.ondataavailable = handleDataAvailable; // Collect recorded data chunks
            mediaRecorder.onstop = handleStop; // Finalize recording when stopped
            mediaRecorder.onerror = (event) => { // Handle recording errors
                 console.error("MediaRecorder Error:", event.error);
                 alert(`Recording Error: ${event.error.name}\n${event.error.message}`);
                 stopRecording(); // Attempt to stop cleanly on error
            };

            // 6. Start Recording
            mediaRecorder.start(1000); // Collect data in chunks (e.g., every 1 second)
            console.log("MediaRecorder started.");

            // Update UI
            startRecBtn.disabled = true;
            stopRecBtn.disabled = false;
            startRecBtn.classList.add('recording');
            startRecBtn.textContent = 'Recording...';

            // Start BGM if one is selected
            changeBgm(); // This will check selection and start if appropriate
        }
        function handleDataAvailable(event) {
            if (event.data && event.data.size > 0) {
                recordedChunks.push(event.data);
                // console.log(`Recorded chunk size: ${event.data.size}`);
            }
        }
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === "recording") {
                mediaRecorder.stop(); // Triggers the 'onstop' event
                console.log("MediaRecorder stopping...");
            } else {
                 console.log("MediaRecorder is not recording or already stopped.");
            }
            stopCurrentBgm(); // Ensure BGM stops when recording stops

            // Update UI
            startRecBtn.disabled = false; // Re-enable start button
            stopRecBtn.disabled = true;
            startRecBtn.classList.remove('recording');
            startRecBtn.textContent = 'Start Recording';
        }
        function handleStop() {
            console.log("MediaRecorder stopped. Processing data...");
             if (recordedChunks.length === 0) {
                 console.warn("No data chunks were recorded. Cannot create video file.");
                 alert("Recording failed to capture data. Please check console for errors.");
                 return;
             }
            // Combine recorded chunks into a single Blob
            const blob = new Blob(recordedChunks, {
                type: mediaRecorder.mimeType || 'video/webm'
            });
            recordedChunks = []; // Clear chunks for next recording

            // Create a downloadable URL for the Blob
            const url = URL.createObjectURL(blob);
            downloadLink.href = url;
            // Create a unique filename with timestamp
            downloadLink.download = `recording-${new Date().toISOString().slice(0,19).replace(/[:T]/g,'-')}.webm`;
            downloadLink.style.display = 'inline-block'; // Show the download link
            console.log(`Recording ready: ${downloadLink.download}, Size: ${(blob.size / 1024 / 1024).toFixed(2)} MB`);
            // Note: User needs to click the link to download.
        }

        // --- Drag and Drop Logic ---
        function onDragStart(event) {
            // Store reference to the item being dragged
            dragTarget = this;
            // this.data = event.data; // Pixi v6/7 might use event directly
            this.alpha = 0.7; // Make semi-transparent during drag
            this.dragging = true;

            // Bring the dragged item to the top *within its layer* for visual feedback
            if (this.parent === graphicsContainer && graphicsContainer.children.length > 1) {
                // Bring graphics overlays to the top of the graphics container
                graphicsContainer.removeChild(this);
                graphicsContainer.addChild(this);
            }
            // Video sprite is in its own layer, no global reordering needed.

            event.stopPropagation(); // Prevent event bubbling up (e.g., to stage)
        }
        function onDragEnd() {
            if (this.dragging) {
                this.alpha = 1; // Restore full opacity
                this.dragging = false;
                // this.data = null;
                dragTarget = null; // Clear drag target reference
            }
        }
        function onDragMove(event) {
            if (this.dragging && dragTarget === this) { // Ensure we're moving the intended target
                const newPosition = event.data.getLocalPosition(this.parent);

                // Calculate proposed new position
                // Since anchor is (0,0) for video, newPosition is roughly the top-left target
                // For text/shapes with anchor (0.5, 0.5), need adjustment or just use delta if preferred
                this.x = newPosition.x - (this.anchor.x * this.width / this.scale.x); // Adjust for anchor if not 0
                this.y = newPosition.y - (this.anchor.y * this.height / this.scale.y);

                // --- Optional: Clamp position to keep sprite within canvas bounds ---
                const bounds = this.getBounds(); // Get current visual bounds
                const parentWidth = this.parent.width || pixiApp.screen.width;
                const parentHeight = this.parent.height || pixiApp.screen.height;

                // Prevent dragging entirely off-screen
                this.x = Math.max(-bounds.width * 0.8, Math.min(this.x, parentWidth - bounds.width * 0.2)); // Allow slight overlap off-screen
                this.y = Math.max(-bounds.height * 0.8, Math.min(this.y, parentHeight - bounds.height * 0.2));
            }
        }

        // --- Overlay/View Functions ---
        function addTextOverlay() {
            if (!pixiApp || !textInput.value.trim()) return; // Need Pixi and text content

            const textStyle = new PIXI.TextStyle({
                 fontFamily: 'Arial',
                 fontSize: parseInt(textSize.value) || 24,
                 fill: textColor.value || "#FFFF00",
                 stroke: '#000000', // Black stroke for visibility
                 strokeThickness: 4,
                 dropShadow: true,
                 dropShadowColor: '#000000',
                 dropShadowBlur: 4,
                 dropShadowDistance: 2,
                 wordWrap: true, // Enable wrapping
                 wordWrapWidth: pixiApp.screen.width * 0.8 // Max width before wrap
            });

            const text = new PIXI.Text(textInput.value, textStyle);
            text.anchor.set(0.5); // Center anchor for easier positioning/rotation
            text.x = pixiApp.screen.width / 2; // Initial position center
            text.y = 60; // Initial position near top

            // Make text interactive and draggable
            text.interactive = true;
            text.buttonMode = true;
            text.cursor = 'move';
            text.on('pointerdown', onDragStart)
                .on('pointerup', onDragEnd)
                .on('pointerupoutside', onDragEnd)
                .on('pointermove', onDragMove);

            graphicsContainer.addChild(text); // Add to the top graphics layer
            // textInput.value = ''; // Optional: Clear input after adding
        }
        function addShapeOverlay(event) {
            if (!pixiApp) return; // Need Pixi initialized

            const button = event.currentTarget;
            const shapeType = button.getAttribute('data-shape');
            const size = parseInt(shapeSize.value) || 50;
            const color = parseInt(shapeColor.value.replace('#', '0x')) || 0xff0000;

            let shape = new PIXI.Graphics();
            shape.beginFill(color, 0.8); // Use slight transparency
            shape.lineStyle(2, 0x000000, 0.8); // Add subtle outline

            // Draw requested shape centered at (0,0) relative to its own origin
            switch (shapeType) {
                case 'circle': shape.drawCircle(0, 0, size / 2); break;
                case 'rectangle': shape.drawRect(-size/2, -size/2, size, size); break;
                case 'triangle': shape.moveTo(0, -size/2); shape.lineTo(size/2, size/2); shape.lineTo(-size/2, size/2); shape.closePath(); break;
                case 'star': shape.drawStar(0, 0, 5, size / 2, size / 4, 0); break; // 5 points, outer radius, inner radius, rotation
                default: console.warn("Unknown shape type:", shapeType); shape = null;
            }
            shape.endFill();

            if (shape) {
                // Position randomly within a central area initially
                shape.x = Math.random() * (pixiApp.screen.width * 0.7) + pixiApp.screen.width * 0.15;
                shape.y = Math.random() * (pixiApp.screen.height * 0.6) + pixiApp.screen.height * 0.2;

                // Make shape interactive and draggable
                shape.interactive = true;
                shape.buttonMode = true;
                shape.cursor = 'move';
                shape.on('pointerdown', onDragStart)
                     .on('pointerup', onDragEnd)
                     .on('pointerupoutside', onDragEnd)
                     .on('pointermove', onDragMove);

                graphicsContainer.addChild(shape); // Add to the top graphics layer
            }
        }
        function clearAllGraphics() {
            if (graphicsContainer) {
                 // Remove all children (text, shapes) from the graphics container
                 while(graphicsContainer.children.length > 0) {
                     const child = graphicsContainer.removeChildAt(0);
                     child.destroy({ children: true }); // Destroy the PIXI object to free memory
                 }
                 console.log("Cleared all text & shapes overlays.");
            }
        }
        function handleCameraScaleChange() {
            if (!videoSprite || !pixiApp) return;
            const scale = parseFloat(cameraScaleSlider.value);
            // Store current center point
            const centerX = videoSprite.x + (videoSprite.width / 2);
            const centerY = videoSprite.y + (videoSprite.height / 2);

            videoSprite.scale.set(scale); // Apply uniform scaling

            // Recalculate position to keep center point the same (zoom around center)
            videoSprite.x = centerX - (videoSprite.width / 2);
            videoSprite.y = centerY - (videoSprite.height / 2);


            cameraScaleValueSpan.textContent = `${scale.toFixed(1)}x`; // Update UI label

            // Clamp position after scaling to ensure it stays mostly within bounds
            const bounds = videoSprite.getBounds();
            const parentWidth = pixiApp.screen.width;
            const parentHeight = pixiApp.screen.height;
            videoSprite.x = Math.max(-bounds.width * 0.8, Math.min(videoSprite.x, parentWidth - bounds.width * 0.2));
            videoSprite.y = Math.max(-bounds.height * 0.8, Math.min(videoSprite.y, parentHeight - bounds.height * 0.2));
        }
        function resetCameraView() {
             if (!videoSprite || !pixiApp) return;
             // Reset scale
             cameraScaleSlider.value = 1.0;
             const scale = 1.0;
             videoSprite.scale.set(scale);
             cameraScaleValueSpan.textContent = `${scale.toFixed(1)}x`;

             // Reset position to center
             const originalWidth = videoSprite.texture.width; // Use original texture size for centering
             const originalHeight = videoSprite.texture.height;
             videoSprite.x = (pixiApp.screen.width - originalWidth) / 2;
             videoSprite.y = (pixiApp.screen.height - originalHeight) / 2;

             // Reset Mask
             cameraMaskShapeSelect.value = 'none';
             applyCameraMask(); // Apply the 'none' mask setting

             console.log("Camera view (scale, position, mask) reset.");
        }
        function applyCameraMask() {
            if (!videoSprite || !cameraMaskGraphics) {
                console.warn("Cannot apply mask: Video sprite or mask graphics not ready.");
                return;
            }
            const shape = cameraMaskShapeSelect.value;
            cameraMaskGraphics.clear(); // Clear previous mask drawing

            if (shape === 'none') {
                videoSprite.mask = null; // Remove the mask reference
                console.log("Camera mask removed.");
                return;
            }

            // Get original, unscaled dimensions of the video texture
            const texWidth = videoSprite.texture.baseTexture.width; // Use baseTexture for original size
            const texHeight = videoSprite.texture.baseTexture.height;

            if (!texWidth || !texHeight) { // Check if dimensions are valid
                console.warn("Cannot apply mask: Video texture dimensions unavailable.", videoSprite.texture);
                videoSprite.mask = null; // Ensure mask is off if dimensions invalid
                return;
            }

            // Draw the mask shape relative to the videoSprite's LOCAL coordinates (0,0 top-left)
            // Mask needs to be filled with any opaque color (white is conventional)
            cameraMaskGraphics.beginFill(0xFFFFFF);

            switch (shape) {
                case 'circle':
                    cameraMaskGraphics.drawCircle(texWidth / 2, texHeight / 2, Math.min(texWidth, texHeight) / 2);
                    break;
                case 'ellipse':
                    cameraMaskGraphics.drawEllipse(texWidth / 2, texHeight / 2, texWidth / 2, texHeight / 2);
                    break;
                case 'rounded_rect':
                    const cornerRadius = Math.min(texWidth, texHeight) * 0.15; // Adjust corner roundness
                    cameraMaskGraphics.drawRoundedRect(0, 0, texWidth, texHeight, cornerRadius);
                    break;
                case 'star':
                    const outerRadius = Math.min(texWidth, texHeight) / 2;
                    const innerRadius = outerRadius * 0.5; // Star point depth
                    cameraMaskGraphics.drawStar(texWidth / 2, texHeight / 2, 5, outerRadius, innerRadius, -Math.PI / 2); // Rotate star to point up
                    break;
            }
            cameraMaskGraphics.endFill();

            // Assign the graphics object as the mask for the video sprite
            videoSprite.mask = cameraMaskGraphics;
            console.log(`Applied camera mask: ${shape}`);
        }

        // --- Background Functions ---
        function updateBackground() {
            if (!pixiApp || !backgroundSprite) return;
            const selection = bgSelect.value;

            // Show/hide color picker based on selection
            bgColorPicker.style.display = (selection === 'color') ? 'inline-block' : 'none';

            if (selection === 'color') {
                const colorValue = PIXI.utils.string2hex(bgColorPicker.value);
                pixiApp.renderer.backgroundColor = colorValue; // Set renderer background color
                pixiApp.renderer.backgroundAlpha = 1; // Ensure it's fully opaque
                backgroundSprite.texture = PIXI.Texture.EMPTY; // Clear sprite texture (don't show image)
                console.log("Background set to color:", bgColorPicker.value);
            } else {
                // Use an image background - make renderer transparent so sprite shows
                pixiApp.renderer.backgroundColor = 0x000000; // Fallback color if image fails
                pixiApp.renderer.backgroundAlpha = 0; // Make renderer transparent

                const imageUrl = PRESET_BACKGROUNDS[selection];
                if (imageUrl) {
                    // Use Pixi's loader cache or load if needed
                    PIXI.Loader.shared.add(imageUrl).load((loader, resources) => {
                          const resource = resources[imageUrl];
                          if (resource && resource.texture) {
                              // Check selection hasn't changed while loading
                              if (bgSelect.value === selection) {
                                   backgroundSprite.texture = resource.texture;
                                   console.log("Loaded background image:", selection);
                                   adjustBackgroundSize(); // Fit/fill the canvas
                              }
                          } else {
                              console.error("Failed to load background resource:", imageUrl, resource?.error);
                              if (bgSelect.value === selection) { // Revert to color if load failed
                                   bgSelect.value = 'color';
                                   updateBackground();
                              }
                          }
                    });
                    // Show placeholder while loading? (Optional)
                    // backgroundSprite.texture = PIXI.Texture.WHITE; backgroundSprite.tint = 0xAAAAAA;
                } else {
                     console.warn("Preset background URL missing for:", selection);
                     backgroundSprite.texture = PIXI.Texture.EMPTY; // Clear texture
                }
            }
        }
        function handleBackgroundUpload(event) {
            const file = event.target.files[0];
            if (file && file.type.startsWith('image/')) {
                const reader = new FileReader();
                reader.onload = (e) => {
                    const imageUrl = e.target.result; // This is a Data URL
                    // PIXI can load Data URLs directly
                    const texture = PIXI.Texture.from(imageUrl);

                    // Ensure renderer is transparent for image background
                    pixiApp.renderer.backgroundColor = 0x000000;
                    pixiApp.renderer.backgroundAlpha = 0;

                    backgroundSprite.texture = texture;
                    console.log("Uploaded background image set.");
                    adjustBackgroundSize(); // Fit/fill canvas

                    // Visually indicate upload is active (optional)
                    // You could add an <option value="uploaded">Uploaded Image</option> and select it
                    // Or simply reset the dropdown to avoid confusion
                     bgSelect.value = 'color'; // Reset dropdown
                     bgColorPicker.style.display = 'none'; // Hide color picker
                }
                reader.onerror = (e) => {
                    console.error("File reading error:", e);
                    alert("Error reading the selected image file.");
                }
                reader.readAsDataURL(file);
            } else if (file) {
                 alert("Please select a valid image file (e.g., JPG, PNG, GIF).");
            }
             // Clear the input so the same file can be re-selected after an error or change
             event.target.value = null;
        }
         function adjustBackgroundSize() {
             // Scale background to cover canvas while maintaining aspect ratio ("cover" behavior)
             if (!backgroundSprite || !backgroundSprite.texture || backgroundSprite.texture === PIXI.Texture.EMPTY) return;

             const tex = backgroundSprite.texture.baseTexture; // Use baseTexture for original dimensions
             const canvasWidth = pixiApp.screen.width;
             const canvasHeight = pixiApp.screen.height;
             const canvasRatio = canvasWidth / canvasHeight;
             const bgRatio = tex.width / tex.height;

             if (canvasRatio > bgRatio) { // Canvas is wider than image aspect ratio
                 backgroundSprite.width = canvasWidth;
                 backgroundSprite.height = canvasWidth / bgRatio;
             } else { // Canvas is taller or same ratio
                 backgroundSprite.height = canvasHeight;
                 backgroundSprite.width = canvasHeight * bgRatio;
             }
             // Center the potentially oversized background image
             backgroundSprite.x = (canvasWidth - backgroundSprite.width) / 2;
             backgroundSprite.y = (canvasHeight - backgroundSprite.height) / 2;
         }

        // --- Audio Control Functions ---
        function changeBgm() {
             stopCurrentBgm(); // Stop any existing BGM
             const selectedBgm = bgmSelect.value;
             console.log("BGM selection changed to:", selectedBgm);
             if (selectedBgm !== 'none' && bgmSounds[selectedBgm]) {
                  // Resume audio context if needed
                  if (audioContext && audioContext.state === 'suspended') { audioContext.resume().catch(e=>console.error("Audio resume failed", e)); }
                 // Only auto-play BGM if currently recording
                 if (mediaRecorder && mediaRecorder.state === 'recording') {
                     bgmSounds[selectedBgm]();
                 } else {
                      console.log("BGM selected, will start playing automatically when recording starts.");
                 }
             }
        }
        function updateBgmVolume() {
            if (bgmGainNode && audioContext) {
                 const volumeValue = parseFloat(bgmVolume.value);
                 // Use setTargetAtTime for smooth volume transition
                 bgmGainNode.gain.setTargetAtTime(volumeValue, audioContext.currentTime, 0.02);
            }
        }

        // --- Start the Application ---
         document.addEventListener('DOMContentLoaded', () => {
            // Setup essential listeners but wait for user interaction (Start Camera) to initialize fully
            setupEventListeners();
            // Initial UI state
            bgColorPicker.style.display = 'inline-block'; // Show color picker by default
             console.log("Application Ready. Click 'Start Camera' to begin.");
        });

        // --- Cleanup ---
        window.onbeforeunload = () => {
             console.log("Cleaning up before page unload...");
             // Stop media streams
             webcamStream?.getTracks().forEach(track => track.stop());
             combinedStream?.getTracks().forEach(track => track.stop());
             webcamStream = null;
             combinedStream = null;

             // Stop recording if active
             if (mediaRecorder && mediaRecorder.state === "recording") {
                 mediaRecorder.onstop = null; // Prevent handleStop from running on forced stop
                 mediaRecorder.stop();
                 mediaRecorder = null;
                 console.log("Forcibly stopped recording.");
             }
             // Stop BGM loop
             stopCurrentBgm();

             // Close audio context
             if(audioContext && audioContext.state !== 'closed') {
                 audioContext.close().then(() => console.log("AudioContext closed.")).catch(e => console.warn("Error closing AudioContext:", e));
                 audioContext = null;
             }

             // Destroy Pixi application and release resources
             if (pixiApp) {
                console.log("Destroying Pixi Application...");
                pixiApp.destroy(true, { children: true, texture: true, baseTexture: true }); // Full cleanup
                pixiApp = null;
                console.log("Pixi Application destroyed.");
             }
        };

    </script>

</body>
</html>